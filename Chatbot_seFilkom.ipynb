{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS2NGidLpY7f"
      },
      "source": [
        "# Download intent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcb_HdSWvGwv"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sV6h5ctRpsN_"
      },
      "outputs": [],
      "source": [
        "from email import message\n",
        "import json\n",
        "import random\n",
        "import string\n",
        "from unittest import result\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import tensorflow as tf\n",
        "import joblib\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "import pickle\n",
        "\n",
        "import re\n",
        "import math\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w184H-8pvSO",
        "outputId": "86b1790e-e7d5-46bf-9d54-9122340b0636"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /home/alfirsafauzulh@student.ub.ac.id/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /home/alfirsafauzulh@student.ub.ac.id/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     /home/alfirsafauzulh@student.ub.ac.id/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-10-14 05:55:05--  https://raw.githubusercontent.com/AndiAlifs/Halofilkom_dump/master/intents_newV2SiPalingClean_v2.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53101 (52K) [text/plain]\n",
            "Saving to: 'intents_newV2SiPalingClean_v2.json'\n",
            "\n",
            "intents_newV2SiPali 100%[===================>]  51.86K   311KB/s    in 0.2s    \n",
            "\n",
            "2022-10-14 05:55:06 (311 KB/s) - 'intents_newV2SiPalingClean_v2.json' saved [53101/53101]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \"https://raw.githubusercontent.com/AndiAlifs/Halofilkom_dump/master/intents_newV2SiPalingClean_v2.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EWIpx728pxAM"
      },
      "outputs": [],
      "source": [
        "f = open(\"intents_newV2SiPalingClean_v2.json\")\n",
        "data = json.load(f)\n",
        "f.close()\n",
        "\n",
        "# Mendapatkan Penggalan Kata\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "e6QoBMYlpywx"
      },
      "outputs": [],
      "source": [
        "# Menampung Penggalan Kata\n",
        "words = []\n",
        "classes = []\n",
        "doc_X = []\n",
        "doc_Y = []\n",
        "\n",
        "for intent in data[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        token = nltk.word_tokenize(pattern)\n",
        "        words.extend(token)\n",
        "        doc_X.append(pattern)\n",
        "        doc_Y.append(intent[\"tag\"])\n",
        "\n",
        "# Menambahkan tag jika belum tersedia\n",
        "    if intent[\"tag\"] not in \"classes\":\n",
        "        classes.append(intent[\"tag\"])\n",
        "\n",
        "# stemmer = StemmerFactory().create_stemmer()\n",
        "\n",
        "words = [word.lower() for word in words if word not in string.punctuation and len(word) > 2]\n",
        "words = sorted(set(words))\n",
        "classes = sorted(set(classes))\n",
        "\n",
        "# List training Data\n",
        "training = []\n",
        "out_empty = [0] * len(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8vem08LVswo6"
      },
      "outputs": [],
      "source": [
        "d = {'patterns': doc_X, 'classes': doc_Y}\n",
        "df = pd.DataFrame(data=d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCNYRmzpDulE",
        "outputId": "b3cf554f-91cd-452d-8171-afe9fb1f53ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tata cara pembayaran                                                        110\n",
              "kriteria 50                                                                  48\n",
              "pengajuan bantuan                                                            37\n",
              "tahapan pendaftaran wisuda                                                   35\n",
              "pencairan saldo ukt                                                          17\n",
              "cek siam untuk tagihan                                                       15\n",
              "psik  permasalahan telah diproses tiket ditutup                              11\n",
              " kkn 2020                                                                     9\n",
              "surat aktif kuliah                                                            7\n",
              "angsur sap                                                                    7\n",
              "bantuan ukt                                                                   5\n",
              "sapaan                                                                        5\n",
              "pengajuan proposal skripsi di luar jadwal jtif                                5\n",
              "penutup                                                                       4\n",
              "permasalahan sibaku                                                           4\n",
              "bantuan ukt dan ukt kemendikbud ristek                                        4\n",
              "jadwal bantuan                                                                4\n",
              "validasi krs jtif terlambat                                                   3\n",
              "yudisium                                                                      3\n",
              "banding ukt mahasiswa                                                         3\n",
              "foto yudisium                                                                 3\n",
              "layanan                                                                       2\n",
              "surat pengantar penelitian skripsi                                            2\n",
              "perubahan judul skripsi filkom apps                                           2\n",
              "cara daftar bantuan kemendikbud ristek                                        2\n",
              "bebas pustaka ub                                                              2\n",
              "skl  transkrip                                                                2\n",
              "pengambilan sertifikat toefl                                                  2\n",
              "permohonan perpanjangan mahasiswa do diluar skripsi                           2\n",
              "pengajuan transkrip keperluan beasiswa mhs do semhas validasi kps dll         2\n",
              "perpanjangan skripsi                                                          1\n",
              "perkuliahan hybrid                                                            1\n",
              "syarat menempuh mk lintas prodi                                               1\n",
              "status wisuda belum valid                                                     1\n",
              "bebas tanggungan laboratorium filkom ub                                       1\n",
              "tidak dapat upload berkas yudisium                                            1\n",
              "prosedur buka blokir telat pembayaran  pengajuan validasi di luar jadwal      1\n",
              "  perubahan judul skripsi                                                     1\n",
              "layanan ruang baca filkom ub                                                  1\n",
              "prasyarat perpindahan stream keminatan                                        1\n",
              "tidak bisa mengikuti perkuliahan luring hybrid                                1\n",
              "pengajuan nilai praktikum                                                     1\n",
              "pencairan beasiswa kemendikbud                                                1\n",
              "pengambilan ijazah non prosesi                                                1\n",
              "ujian khusus filkom ub                                                        1\n",
              "nilai mbkm belum keluar 20212                                                 1\n",
              " turnitin                                                                     1\n",
              "skl dan transkrip sementara                                                   1\n",
              "registrasi mahasiswa lama                                                     1\n",
              "Name: classes, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['classes'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mEsH27Bdp2Ve"
      },
      "outputs": [],
      "source": [
        "training = []\n",
        "\n",
        "# Membuat Model Training Chatbot\n",
        "for idx, doc in enumerate(doc_X):\n",
        "    bow = []\n",
        "    text = doc.lower()\n",
        "    # text = stemmer.stem(text)\n",
        "    for word in words:\n",
        "        bow.append(1) if word in text else bow.append(0)\n",
        "\n",
        "    # membuat urutan index untuk class\n",
        "    output_row = list(out_empty)\n",
        "    output_row[classes.index(doc_Y[idx])] += 1\n",
        "\n",
        "    # add the one hot encoded BoW and associated classes to training\n",
        "    training.append([bow, output_row])\n",
        "\n",
        "# add no response training\n",
        "bow = [0 for i in range(len(words))]\n",
        "output_row = list(out_empty)\n",
        "output_row[classes.index('no_response')] += 1\n",
        "training.append([bow, output_row])\n",
        "\n",
        "# shuffle the data and convert it to an array\n",
        "random.shuffle(training)\n",
        "training = np.array(training, dtype=object)\n",
        "\n",
        "# split the features and target labels\n",
        "train_X = np.array(list(training[:, 0]))\n",
        "train_y = np.array(list(training[:, 1]))\n",
        "\n",
        "# defining some parameters\n",
        "input_shape = (len(train_X[0]),)\n",
        "output_shape = len(train_y[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvshdtD3x9I9"
      },
      "source": [
        "# Training model ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbJZUv-Hu0r2",
        "outputId": "fc574e89-5b62-4405-a929-b5c1db9d46d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00         1\n",
            "           3       1.00      1.00      1.00         7\n",
            "           4       1.00      1.00      1.00         3\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      0.50      0.67         4\n",
            "           7       1.00      1.00      1.00         2\n",
            "           8       1.00      1.00      1.00         1\n",
            "           9       1.00      1.00      1.00         2\n",
            "          10       1.00      1.00      1.00        15\n",
            "          11       1.00      1.00      1.00         3\n",
            "          12       1.00      1.00      1.00         4\n",
            "          13       1.00      0.96      0.98        48\n",
            "          14       1.00      1.00      1.00         2\n",
            "          15       1.00      1.00      1.00         1\n",
            "          16       1.00      1.00      1.00         1\n",
            "          17       0.00      0.00      0.00         1\n",
            "          18       1.00      1.00      1.00         1\n",
            "          19       1.00      1.00      1.00        17\n",
            "          20       0.97      0.97      0.97        37\n",
            "          21       1.00      1.00      1.00         1\n",
            "          22       1.00      1.00      1.00         5\n",
            "          23       1.00      1.00      1.00         2\n",
            "          24       1.00      1.00      1.00         1\n",
            "          25       1.00      1.00      1.00         2\n",
            "          26       1.00      1.00      1.00         4\n",
            "          27       1.00      1.00      1.00         1\n",
            "          28       1.00      1.00      1.00         4\n",
            "          29       1.00      1.00      1.00         2\n",
            "          30       1.00      1.00      1.00         1\n",
            "          31       1.00      1.00      1.00         2\n",
            "          32       1.00      1.00      1.00         1\n",
            "          33       1.00      1.00      1.00         1\n",
            "          34       1.00      1.00      1.00        11\n",
            "          35       1.00      1.00      1.00         1\n",
            "          36       1.00      1.00      1.00         5\n",
            "          37       1.00      1.00      1.00         2\n",
            "          38       1.00      1.00      1.00         1\n",
            "          39       1.00      1.00      1.00         1\n",
            "          40       1.00      1.00      1.00         7\n",
            "          41       1.00      1.00      1.00         2\n",
            "          42       1.00      1.00      1.00         1\n",
            "          43       1.00      1.00      1.00        35\n",
            "          44       0.99      0.98      0.99       110\n",
            "          45       1.00      1.00      1.00         1\n",
            "          46       1.00      1.00      1.00         1\n",
            "          47       1.00      1.00      1.00         1\n",
            "          48       1.00      1.00      1.00         3\n",
            "          49       1.00      1.00      1.00         3\n",
            "\n",
            "   micro avg       0.99      0.98      0.99       377\n",
            "   macro avg       0.98      0.97      0.97       377\n",
            "weighted avg       0.99      0.98      0.98       377\n",
            " samples avg       0.98      0.98      0.98       377\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/alfirsafauzulh@student.ub.ac.id/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/alfirsafauzulh@student.ub.ac.id/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# machine learning model\n",
        "model_ml = RandomForestClassifier()\n",
        "model_ml.fit(train_X, train_y)\n",
        "y_preds = model_ml.predict(train_X)\n",
        "print(classification_report(train_y, y_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljRI1YOcx6DM"
      },
      "source": [
        "# Training model DL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXnzaBS4imiR"
      },
      "outputs": [],
      "source": [
        "# cb = tf.keras.callbacks.EarlyStopping(\n",
        "#     monitor='accuracy',\n",
        "#     patience=3,\n",
        "#     verbose=1,\n",
        "#     mode='auto',\n",
        "#     restore_best_weights=True\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bX1eWJE9syIc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "# fix random seed for reproducibility\n",
        "tf.random.set_seed(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw20-oFCp5cn",
        "outputId": "8e6b5f4e-ce82-4204-d32d-448a2e67e069"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_123 (Dense)            (None, 256)               84992     \n",
            "_________________________________________________________________\n",
            "dense_124 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_125 (Dense)            (None, 50)                6450      \n",
            "=================================================================\n",
            "Total params: 124,338\n",
            "Trainable params: 124,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 2.8504 - accuracy: 0.3333 - val_loss: 2.1868 - val_accuracy: 0.5263\n",
            "Epoch 2/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.6281 - accuracy: 0.5929 - val_loss: 2.0387 - val_accuracy: 0.5789\n",
            "Epoch 3/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9585 - accuracy: 0.7522 - val_loss: 2.2377 - val_accuracy: 0.5789\n",
            "Epoch 4/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5613 - accuracy: 0.8319 - val_loss: 2.2799 - val_accuracy: 0.6316\n",
            "Epoch 5/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2884 - accuracy: 0.9469 - val_loss: 3.2340 - val_accuracy: 0.6053\n",
            "Epoch 6/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1345 - accuracy: 0.9705 - val_loss: 3.0756 - val_accuracy: 0.6579\n",
            "Epoch 7/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0867 - accuracy: 0.9764 - val_loss: 3.8393 - val_accuracy: 0.6579\n",
            "Epoch 8/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0738 - accuracy: 0.9735 - val_loss: 3.4695 - val_accuracy: 0.6579\n",
            "Epoch 9/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0500 - accuracy: 0.9794 - val_loss: 3.9753 - val_accuracy: 0.6579\n",
            "Epoch 10/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0549 - accuracy: 0.9823 - val_loss: 3.7785 - val_accuracy: 0.5263\n",
            "Epoch 11/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0416 - accuracy: 0.9823 - val_loss: 4.3666 - val_accuracy: 0.6316\n",
            "Epoch 12/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0378 - accuracy: 0.9882 - val_loss: 4.5782 - val_accuracy: 0.5526\n",
            "Epoch 13/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9882 - val_loss: 4.3075 - val_accuracy: 0.5789\n",
            "Epoch 14/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 0.9853 - val_loss: 4.5552 - val_accuracy: 0.5789\n",
            "Epoch 15/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9882 - val_loss: 4.3720 - val_accuracy: 0.5789\n",
            "Epoch 16/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 0.9882 - val_loss: 4.4805 - val_accuracy: 0.6053\n",
            "Epoch 17/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0295 - accuracy: 0.9882 - val_loss: 4.7824 - val_accuracy: 0.5789\n",
            "Epoch 18/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9882 - val_loss: 4.5400 - val_accuracy: 0.5526\n",
            "Epoch 19/150\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0293 - accuracy: 0.9882 - val_loss: 4.6202 - val_accuracy: 0.6053\n",
            "Epoch 20/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0300 - accuracy: 0.9882 - val_loss: 4.6285 - val_accuracy: 0.6053\n",
            "Epoch 21/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0209 - accuracy: 0.9853 - val_loss: 4.5931 - val_accuracy: 0.6053\n",
            "Epoch 22/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0184 - accuracy: 0.9912 - val_loss: 4.7396 - val_accuracy: 0.6053\n",
            "Epoch 23/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0175 - accuracy: 0.9882 - val_loss: 4.8025 - val_accuracy: 0.6053\n",
            "Epoch 24/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0196 - accuracy: 0.9853 - val_loss: 4.8038 - val_accuracy: 0.6053\n",
            "Epoch 25/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0206 - accuracy: 0.9882 - val_loss: 4.8828 - val_accuracy: 0.6053\n",
            "Epoch 26/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0149 - accuracy: 0.9912 - val_loss: 4.7402 - val_accuracy: 0.6053\n",
            "Epoch 27/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0162 - accuracy: 0.9853 - val_loss: 4.7963 - val_accuracy: 0.6053\n",
            "Epoch 28/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0164 - accuracy: 0.9912 - val_loss: 4.8848 - val_accuracy: 0.5789\n",
            "Epoch 29/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 0.9853 - val_loss: 5.0603 - val_accuracy: 0.6053\n",
            "Epoch 30/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0188 - accuracy: 0.9853 - val_loss: 4.8444 - val_accuracy: 0.6053\n",
            "Epoch 31/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0156 - accuracy: 0.9853 - val_loss: 4.9957 - val_accuracy: 0.6053\n",
            "Epoch 32/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0156 - accuracy: 0.9882 - val_loss: 5.0666 - val_accuracy: 0.6053\n",
            "Epoch 33/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0170 - accuracy: 0.9853 - val_loss: 4.9940 - val_accuracy: 0.6053\n",
            "Epoch 34/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0164 - accuracy: 0.9882 - val_loss: 5.2264 - val_accuracy: 0.6053\n",
            "Epoch 35/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0161 - accuracy: 0.9853 - val_loss: 5.1561 - val_accuracy: 0.6053\n",
            "Epoch 36/150\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0137 - accuracy: 0.9912 - val_loss: 5.1378 - val_accuracy: 0.6053\n",
            "Epoch 37/150\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0174 - accuracy: 0.9853 - val_loss: 5.1561 - val_accuracy: 0.6053\n",
            "Epoch 38/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0154 - accuracy: 0.9882 - val_loss: 5.2475 - val_accuracy: 0.6053\n",
            "Epoch 39/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0175 - accuracy: 0.9912 - val_loss: 5.2091 - val_accuracy: 0.6053\n",
            "Epoch 40/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0150 - accuracy: 0.9882 - val_loss: 5.2388 - val_accuracy: 0.6053\n",
            "Epoch 41/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0160 - accuracy: 0.9853 - val_loss: 5.1269 - val_accuracy: 0.6053\n",
            "Epoch 42/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0153 - accuracy: 0.9912 - val_loss: 5.1713 - val_accuracy: 0.6053\n",
            "Epoch 43/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0159 - accuracy: 0.9823 - val_loss: 5.2698 - val_accuracy: 0.6053\n",
            "Epoch 44/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0165 - accuracy: 0.9882 - val_loss: 5.2157 - val_accuracy: 0.5789\n",
            "Epoch 45/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0149 - accuracy: 0.9853 - val_loss: 5.2021 - val_accuracy: 0.6053\n",
            "Epoch 46/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0177 - accuracy: 0.9853 - val_loss: 5.1805 - val_accuracy: 0.6053\n",
            "Epoch 47/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0152 - accuracy: 0.9912 - val_loss: 5.2835 - val_accuracy: 0.6053\n",
            "Epoch 48/150\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0155 - accuracy: 0.9882 - val_loss: 5.2686 - val_accuracy: 0.6053\n",
            "Epoch 49/150\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0151 - accuracy: 0.9882 - val_loss: 5.3790 - val_accuracy: 0.6053\n",
            "Epoch 50/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0146 - accuracy: 0.9882 - val_loss: 5.3412 - val_accuracy: 0.6053\n",
            "Epoch 51/150\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0131 - accuracy: 0.9912 - val_loss: 5.4941 - val_accuracy: 0.5789\n",
            "Epoch 52/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0165 - accuracy: 0.9912 - val_loss: 5.3996 - val_accuracy: 0.6053\n",
            "Epoch 53/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0161 - accuracy: 0.9882 - val_loss: 5.3433 - val_accuracy: 0.6053\n",
            "Epoch 54/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0142 - accuracy: 0.9912 - val_loss: 5.3761 - val_accuracy: 0.6053\n",
            "Epoch 55/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0150 - accuracy: 0.9882 - val_loss: 5.4381 - val_accuracy: 0.6053\n",
            "Epoch 56/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0135 - accuracy: 0.9882 - val_loss: 5.3965 - val_accuracy: 0.6053\n",
            "Epoch 57/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0147 - accuracy: 0.9882 - val_loss: 5.4409 - val_accuracy: 0.6053\n",
            "Epoch 58/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0179 - accuracy: 0.9853 - val_loss: 5.6097 - val_accuracy: 0.6053\n",
            "Epoch 59/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0145 - accuracy: 0.9912 - val_loss: 5.4408 - val_accuracy: 0.6053\n",
            "Epoch 60/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0144 - accuracy: 0.9882 - val_loss: 5.4040 - val_accuracy: 0.5789\n",
            "Epoch 61/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 0.9912 - val_loss: 5.6179 - val_accuracy: 0.6053\n",
            "Epoch 62/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0146 - accuracy: 0.9853 - val_loss: 5.6435 - val_accuracy: 0.5789\n",
            "Epoch 63/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0147 - accuracy: 0.9853 - val_loss: 5.6770 - val_accuracy: 0.6053\n",
            "Epoch 64/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0137 - accuracy: 0.9912 - val_loss: 5.6849 - val_accuracy: 0.6053\n",
            "Epoch 65/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0158 - accuracy: 0.9882 - val_loss: 5.5706 - val_accuracy: 0.5789\n",
            "Epoch 66/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 0.9912 - val_loss: 5.6727 - val_accuracy: 0.6053\n",
            "Epoch 67/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0138 - accuracy: 0.9882 - val_loss: 5.7951 - val_accuracy: 0.5789\n",
            "Epoch 68/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0143 - accuracy: 0.9882 - val_loss: 5.7804 - val_accuracy: 0.5789\n",
            "Epoch 69/150\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 0.9882 - val_loss: 5.7329 - val_accuracy: 0.6053\n",
            "Epoch 70/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0158 - accuracy: 0.9853 - val_loss: 5.8361 - val_accuracy: 0.5789\n",
            "Epoch 71/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 0.9912 - val_loss: 5.7457 - val_accuracy: 0.5789\n",
            "Epoch 72/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0154 - accuracy: 0.9882 - val_loss: 5.7157 - val_accuracy: 0.6053\n",
            "Epoch 73/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 0.9882 - val_loss: 5.7010 - val_accuracy: 0.6053\n",
            "Epoch 74/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0141 - accuracy: 0.9912 - val_loss: 5.8041 - val_accuracy: 0.5789\n",
            "Epoch 75/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0138 - accuracy: 0.9912 - val_loss: 5.7482 - val_accuracy: 0.5789\n",
            "Epoch 76/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 0.9853 - val_loss: 5.7358 - val_accuracy: 0.5789\n",
            "Epoch 77/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0131 - accuracy: 0.9912 - val_loss: 5.7531 - val_accuracy: 0.5789\n",
            "Epoch 78/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 0.9882 - val_loss: 5.8754 - val_accuracy: 0.5789\n",
            "Epoch 79/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0148 - accuracy: 0.9882 - val_loss: 5.8536 - val_accuracy: 0.5789\n",
            "Epoch 80/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0142 - accuracy: 0.9912 - val_loss: 5.8273 - val_accuracy: 0.5789\n",
            "Epoch 81/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0141 - accuracy: 0.9853 - val_loss: 5.9616 - val_accuracy: 0.5789\n",
            "Epoch 82/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0144 - accuracy: 0.9882 - val_loss: 5.9276 - val_accuracy: 0.5789\n",
            "Epoch 83/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0138 - accuracy: 0.9912 - val_loss: 5.9778 - val_accuracy: 0.5789\n",
            "Epoch 84/150\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 0.9853 - val_loss: 5.9536 - val_accuracy: 0.5789\n",
            "Epoch 85/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 0.9853 - val_loss: 5.7855 - val_accuracy: 0.5789\n",
            "Epoch 86/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0170 - accuracy: 0.9882 - val_loss: 6.0313 - val_accuracy: 0.6053\n",
            "Epoch 87/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0132 - accuracy: 0.9912 - val_loss: 5.7703 - val_accuracy: 0.5526\n",
            "Epoch 88/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0210 - accuracy: 0.9853 - val_loss: 5.8251 - val_accuracy: 0.5526\n",
            "Epoch 89/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0162 - accuracy: 0.9912 - val_loss: 5.8565 - val_accuracy: 0.5526\n",
            "Epoch 90/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0141 - accuracy: 0.9912 - val_loss: 5.9451 - val_accuracy: 0.5789\n",
            "Epoch 91/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0149 - accuracy: 0.9882 - val_loss: 5.9152 - val_accuracy: 0.5789\n",
            "Epoch 92/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0145 - accuracy: 0.9853 - val_loss: 5.9889 - val_accuracy: 0.5789\n",
            "Epoch 93/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0141 - accuracy: 0.9882 - val_loss: 6.0417 - val_accuracy: 0.5789\n",
            "Epoch 94/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 0.9853 - val_loss: 6.0183 - val_accuracy: 0.6053\n",
            "Epoch 95/150\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0142 - accuracy: 0.9853 - val_loss: 6.0829 - val_accuracy: 0.6053\n",
            "Epoch 96/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0148 - accuracy: 0.9882 - val_loss: 6.1415 - val_accuracy: 0.6053\n",
            "Epoch 97/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0136 - accuracy: 0.9912 - val_loss: 6.0679 - val_accuracy: 0.6053\n",
            "Epoch 98/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 0.9912 - val_loss: 6.0311 - val_accuracy: 0.5789\n",
            "Epoch 99/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0152 - accuracy: 0.9882 - val_loss: 6.1169 - val_accuracy: 0.5789\n",
            "Epoch 100/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0137 - accuracy: 0.9912 - val_loss: 6.1818 - val_accuracy: 0.5789\n",
            "Epoch 101/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0149 - accuracy: 0.9912 - val_loss: 6.3156 - val_accuracy: 0.6053\n",
            "Epoch 102/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0164 - accuracy: 0.9853 - val_loss: 6.3153 - val_accuracy: 0.6053\n",
            "Epoch 103/150\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0179 - accuracy: 0.9882 - val_loss: 5.9500 - val_accuracy: 0.5526\n",
            "Epoch 104/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0138 - accuracy: 0.9882 - val_loss: 5.9481 - val_accuracy: 0.5789\n",
            "Epoch 105/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0135 - accuracy: 0.9912 - val_loss: 6.0851 - val_accuracy: 0.5526\n",
            "Epoch 106/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0150 - accuracy: 0.9882 - val_loss: 6.2259 - val_accuracy: 0.5789\n",
            "Epoch 107/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0135 - accuracy: 0.9912 - val_loss: 6.2401 - val_accuracy: 0.6053\n",
            "Epoch 108/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0139 - accuracy: 0.9912 - val_loss: 6.3542 - val_accuracy: 0.6053\n",
            "Epoch 109/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0128 - accuracy: 0.9912 - val_loss: 6.3461 - val_accuracy: 0.5789\n",
            "Epoch 110/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0142 - accuracy: 0.9912 - val_loss: 6.3789 - val_accuracy: 0.5789\n",
            "Epoch 111/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0141 - accuracy: 0.9882 - val_loss: 6.3730 - val_accuracy: 0.6053\n",
            "Epoch 112/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0156 - accuracy: 0.9882 - val_loss: 6.3852 - val_accuracy: 0.6053\n",
            "Epoch 113/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0137 - accuracy: 0.9882 - val_loss: 6.4105 - val_accuracy: 0.6053\n",
            "Epoch 114/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0143 - accuracy: 0.9912 - val_loss: 6.2126 - val_accuracy: 0.5789\n",
            "Epoch 115/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0177 - accuracy: 0.9912 - val_loss: 6.3809 - val_accuracy: 0.6053\n",
            "Epoch 116/150\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0135 - accuracy: 0.9912 - val_loss: 6.4466 - val_accuracy: 0.5789\n",
            "Epoch 117/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0134 - accuracy: 0.9912 - val_loss: 6.4826 - val_accuracy: 0.5789\n",
            "Epoch 118/150\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0137 - accuracy: 0.9912 - val_loss: 6.4511 - val_accuracy: 0.5789\n",
            "Epoch 119/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0148 - accuracy: 0.9882 - val_loss: 6.4207 - val_accuracy: 0.6053\n",
            "Epoch 120/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0134 - accuracy: 0.9882 - val_loss: 6.4165 - val_accuracy: 0.5789\n",
            "Epoch 121/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0141 - accuracy: 0.9912 - val_loss: 6.5154 - val_accuracy: 0.5789\n",
            "Epoch 122/150\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0135 - accuracy: 0.9882 - val_loss: 6.5736 - val_accuracy: 0.5789\n",
            "Epoch 123/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0138 - accuracy: 0.9912 - val_loss: 6.6410 - val_accuracy: 0.6053\n",
            "Epoch 124/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 0.9882 - val_loss: 6.6355 - val_accuracy: 0.6053\n",
            "Epoch 125/150\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0137 - accuracy: 0.9853 - val_loss: 6.6435 - val_accuracy: 0.6053\n",
            "Epoch 126/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0135 - accuracy: 0.9853 - val_loss: 6.5994 - val_accuracy: 0.5789\n",
            "Epoch 127/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0136 - accuracy: 0.9882 - val_loss: 6.5447 - val_accuracy: 0.6053\n",
            "Epoch 128/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 0.9912 - val_loss: 6.5282 - val_accuracy: 0.5789\n",
            "Epoch 129/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0139 - accuracy: 0.9882 - val_loss: 6.6017 - val_accuracy: 0.5789\n",
            "Epoch 130/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0138 - accuracy: 0.9853 - val_loss: 6.6237 - val_accuracy: 0.5789\n",
            "Epoch 131/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 0.9853 - val_loss: 6.6933 - val_accuracy: 0.5789\n",
            "Epoch 132/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0136 - accuracy: 0.9882 - val_loss: 6.6837 - val_accuracy: 0.6053\n",
            "Epoch 133/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0138 - accuracy: 0.9912 - val_loss: 6.6255 - val_accuracy: 0.5789\n",
            "Epoch 134/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0142 - accuracy: 0.9823 - val_loss: 6.7510 - val_accuracy: 0.6053\n",
            "Epoch 135/150\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0134 - accuracy: 0.9912 - val_loss: 6.7760 - val_accuracy: 0.5789\n",
            "Epoch 136/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 0.9882 - val_loss: 6.7568 - val_accuracy: 0.5789\n",
            "Epoch 137/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0137 - accuracy: 0.9853 - val_loss: 6.6901 - val_accuracy: 0.6053\n",
            "Epoch 138/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 0.9912 - val_loss: 6.6826 - val_accuracy: 0.5789\n",
            "Epoch 139/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0130 - accuracy: 0.9912 - val_loss: 6.8289 - val_accuracy: 0.5789\n",
            "Epoch 140/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0130 - accuracy: 0.9912 - val_loss: 6.9785 - val_accuracy: 0.6053\n",
            "Epoch 141/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0138 - accuracy: 0.9882 - val_loss: 6.8781 - val_accuracy: 0.5789\n",
            "Epoch 142/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0142 - accuracy: 0.9882 - val_loss: 6.8415 - val_accuracy: 0.6053\n",
            "Epoch 143/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 0.9912 - val_loss: 6.6172 - val_accuracy: 0.5526\n",
            "Epoch 144/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0131 - accuracy: 0.9912 - val_loss: 6.6823 - val_accuracy: 0.5789\n",
            "Epoch 145/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 0.9882 - val_loss: 6.7772 - val_accuracy: 0.5789\n",
            "Epoch 146/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0143 - accuracy: 0.9882 - val_loss: 6.8035 - val_accuracy: 0.5789\n",
            "Epoch 147/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0138 - accuracy: 0.9853 - val_loss: 6.7523 - val_accuracy: 0.5789\n",
            "Epoch 148/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0139 - accuracy: 0.9912 - val_loss: 6.9342 - val_accuracy: 0.5789\n",
            "Epoch 149/150\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0143 - accuracy: 0.9882 - val_loss: 6.8863 - val_accuracy: 0.5789\n",
            "Epoch 150/150\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0151 - accuracy: 0.9912 - val_loss: 6.8813 - val_accuracy: 0.6053\n"
          ]
        }
      ],
      "source": [
        "#deep learning model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=input_shape, activation=\"relu\"))\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(output_shape, activation=\"softmax\"))\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "\n",
        "history_dl = model.fit(x=train_X, \n",
        "                       y=train_y,\n",
        "                       epochs=150,\n",
        "                       verbose=1,\n",
        "                       workers = 2,\n",
        "                       validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FDHDr3Gh4rw"
      },
      "source": [
        "# Model Evaluation Performance & Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "jhfz3BsfxzIm",
        "outputId": "74d9daba-72d4-4a1d-acd4-54233b688af2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(history_dl.history['accuracy'])\n",
        "# plt.plot(history_dl.history['val_accuracy'])\n",
        "plt.title('Model Accuracy Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','validation'], loc='upper left') \n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(history_dl.history['loss'])\n",
        "# plt.plot(history_dl.history['val_loss'])\n",
        "plt.title('Model Loss Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','validation'], loc='upper left') \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "gMe8mDkj8bYk",
        "outputId": "7ddb1fb2-80e9-4270-d21a-62aba86587c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "--- Starting trial: run-0\n",
            "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'adam'}\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.8646 - accuracy: 0.0637\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7255 - accuracy: 0.2573\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5356 - accuracy: 0.3050\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.2097 - accuracy: 0.2971\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8691 - accuracy: 0.2971\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6534 - accuracy: 0.2997\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4657 - accuracy: 0.3369\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2739 - accuracy: 0.4164\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2048 - accuracy: 0.4403\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0449 - accuracy: 0.4960\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9959 - accuracy: 0.4987\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8658 - accuracy: 0.5491\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7966 - accuracy: 0.5464\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7239 - accuracy: 0.5862\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6428 - accuracy: 0.5968\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5630 - accuracy: 0.6207\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4716 - accuracy: 0.6207\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4610 - accuracy: 0.6393\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3872 - accuracy: 0.6340\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3348 - accuracy: 0.6711\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2547 - accuracy: 0.6950\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2255 - accuracy: 0.7029\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2198 - accuracy: 0.7029\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1956 - accuracy: 0.6923\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1447 - accuracy: 0.7109\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0666 - accuracy: 0.7241\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0488 - accuracy: 0.7427\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0536 - accuracy: 0.7507\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9671 - accuracy: 0.7533\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9830 - accuracy: 0.7321\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9690 - accuracy: 0.7454\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9122 - accuracy: 0.7586\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9188 - accuracy: 0.7639\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8362 - accuracy: 0.7851\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8194 - accuracy: 0.7905\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7976 - accuracy: 0.7878\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7646 - accuracy: 0.7851\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7795 - accuracy: 0.7878\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7284 - accuracy: 0.8143\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7546 - accuracy: 0.7984\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.8170\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6980 - accuracy: 0.8143\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.8462\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.8488\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.8276\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6028 - accuracy: 0.8276\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.8568\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.8780\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.8382\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.8780\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.9211\n",
            "--- Starting trial: run-1\n",
            "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.8649 - accuracy: 0.0292\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.8440 - accuracy: 0.0981\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.8156 - accuracy: 0.1379\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7769 - accuracy: 0.2175\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7427 - accuracy: 0.2414\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7200 - accuracy: 0.2891\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6830 - accuracy: 0.2838\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6324 - accuracy: 0.2891\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.5905 - accuracy: 0.2891\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.5371 - accuracy: 0.2891\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.4876 - accuracy: 0.2918\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.4186 - accuracy: 0.2918\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.3735 - accuracy: 0.2918\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.2792 - accuracy: 0.2918\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.2213 - accuracy: 0.2918\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1916 - accuracy: 0.2918\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.1375 - accuracy: 0.2918\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.1082 - accuracy: 0.2918\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0551 - accuracy: 0.2918\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0342 - accuracy: 0.2918\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9855 - accuracy: 0.2918\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9662 - accuracy: 0.2918\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.9635 - accuracy: 0.2918\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.9217 - accuracy: 0.2918\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9144 - accuracy: 0.2918\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8884 - accuracy: 0.2918\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.8525 - accuracy: 0.2918\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8369 - accuracy: 0.2918\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.8416 - accuracy: 0.2918\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8120 - accuracy: 0.2891\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8009 - accuracy: 0.2944\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7716 - accuracy: 0.2918\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7591 - accuracy: 0.2944\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7481 - accuracy: 0.2918\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7182 - accuracy: 0.2918\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7372 - accuracy: 0.2944\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6752 - accuracy: 0.2918\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6646 - accuracy: 0.2918\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7167 - accuracy: 0.2971\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6747 - accuracy: 0.3050\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6740 - accuracy: 0.2918\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.6648 - accuracy: 0.2971\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6863 - accuracy: 0.3050\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6361 - accuracy: 0.2997\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6412 - accuracy: 0.2838\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6439 - accuracy: 0.3077\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6209 - accuracy: 0.3050\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6194 - accuracy: 0.3024\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.5768 - accuracy: 0.3130\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5722 - accuracy: 0.2971\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 2.5585 - accuracy: 0.3158\n",
            "--- Starting trial: run-2\n",
            "{'num_units': 32, 'dropout': 0.5, 'optimizer': 'adam'}\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.9291 - accuracy: 0.0239\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.8238 - accuracy: 0.0637\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.7301 - accuracy: 0.1326\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5974 - accuracy: 0.2149\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.3856 - accuracy: 0.2679\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1318 - accuracy: 0.2838\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9399 - accuracy: 0.3130\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7139 - accuracy: 0.3289\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6034 - accuracy: 0.3660\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5462 - accuracy: 0.3475\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.4089 - accuracy: 0.3793\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3539 - accuracy: 0.4111\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.3045 - accuracy: 0.4377\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.0887 - accuracy: 0.4801\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1298 - accuracy: 0.4748\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0398 - accuracy: 0.5040\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0423 - accuracy: 0.4562\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9270 - accuracy: 0.5199\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8652 - accuracy: 0.5252\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8137 - accuracy: 0.5279\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7351 - accuracy: 0.5703\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7127 - accuracy: 0.5942\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7592 - accuracy: 0.5650\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6322 - accuracy: 0.5782\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6606 - accuracy: 0.5650\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6046 - accuracy: 0.5968\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6020 - accuracy: 0.6048\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5282 - accuracy: 0.6021\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5590 - accuracy: 0.5942\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4979 - accuracy: 0.5995\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5066 - accuracy: 0.6048\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4857 - accuracy: 0.6154\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3721 - accuracy: 0.6446\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4488 - accuracy: 0.6207\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3380 - accuracy: 0.6393\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3602 - accuracy: 0.6366\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3480 - accuracy: 0.6472\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2770 - accuracy: 0.6578\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2857 - accuracy: 0.6764\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2913 - accuracy: 0.6525\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2409 - accuracy: 0.6605\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2640 - accuracy: 0.6897\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1981 - accuracy: 0.6976\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1712 - accuracy: 0.6870\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1770 - accuracy: 0.6897\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2037 - accuracy: 0.6764\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1307 - accuracy: 0.6976\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0911 - accuracy: 0.6976\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1173 - accuracy: 0.7003\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1218 - accuracy: 0.7056\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.8730 - accuracy: 0.7895\n",
            "--- Starting trial: run-3\n",
            "{'num_units': 32, 'dropout': 0.5, 'optimizer': 'sgd'}\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.9096 - accuracy: 0.0106\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.9109 - accuracy: 0.0318\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.8611 - accuracy: 0.0345\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.8429 - accuracy: 0.0504\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.8152 - accuracy: 0.0743\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7899 - accuracy: 0.1034\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7555 - accuracy: 0.1167\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7343 - accuracy: 0.1512\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6844 - accuracy: 0.2069\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6776 - accuracy: 0.1989\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6545 - accuracy: 0.2440\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6024 - accuracy: 0.2361\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.5500 - accuracy: 0.2493\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.5225 - accuracy: 0.2706\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.4843 - accuracy: 0.2706\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.4607 - accuracy: 0.2706\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.3924 - accuracy: 0.2944\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.3617 - accuracy: 0.2865\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.2988 - accuracy: 0.2918\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.2546 - accuracy: 0.2997\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.2009 - accuracy: 0.2865\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.1603 - accuracy: 0.2838\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.1454 - accuracy: 0.2944\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0491 - accuracy: 0.2971\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0570 - accuracy: 0.2759\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9981 - accuracy: 0.2971\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0389 - accuracy: 0.2838\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0175 - accuracy: 0.2865\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9223 - accuracy: 0.2865\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9333 - accuracy: 0.2944\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9442 - accuracy: 0.2971\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9026 - accuracy: 0.3050\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8779 - accuracy: 0.2812\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9116 - accuracy: 0.3024\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8653 - accuracy: 0.3024\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8819 - accuracy: 0.2971\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8449 - accuracy: 0.3024\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8702 - accuracy: 0.2865\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8391 - accuracy: 0.2971\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8238 - accuracy: 0.2944\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8295 - accuracy: 0.2785\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7892 - accuracy: 0.2812\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7705 - accuracy: 0.2997\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7152 - accuracy: 0.2944\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.7977 - accuracy: 0.3024\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7394 - accuracy: 0.2865\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.7552 - accuracy: 0.2891\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.7411 - accuracy: 0.2997\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7326 - accuracy: 0.2891\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6805 - accuracy: 0.2918\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 2.6286 - accuracy: 0.3158\n",
            "--- Starting trial: run-4\n",
            "{'num_units': 64, 'dropout': 0.1, 'optimizer': 'adam'}\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7761 - accuracy: 0.1512\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5132 - accuracy: 0.2971\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1062 - accuracy: 0.3156\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7592 - accuracy: 0.2997\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5643 - accuracy: 0.3210\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.3822 - accuracy: 0.3820\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.2745 - accuracy: 0.4111\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1139 - accuracy: 0.4668\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0346 - accuracy: 0.4721\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9203 - accuracy: 0.5385\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8330 - accuracy: 0.5623\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6939 - accuracy: 0.5862\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6329 - accuracy: 0.5995\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5810 - accuracy: 0.6074\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5061 - accuracy: 0.6233\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3897 - accuracy: 0.6525\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3606 - accuracy: 0.6525\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2611 - accuracy: 0.6790\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1998 - accuracy: 0.6844\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1766 - accuracy: 0.7003\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1424 - accuracy: 0.7056\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0888 - accuracy: 0.7109\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0241 - accuracy: 0.7427\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9989 - accuracy: 0.7294\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9731 - accuracy: 0.7533\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9190 - accuracy: 0.7586\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8849 - accuracy: 0.7480\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8289 - accuracy: 0.7851\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8141 - accuracy: 0.7878\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7982 - accuracy: 0.7931\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7468 - accuracy: 0.8196\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7412 - accuracy: 0.8249\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.8462\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6484 - accuracy: 0.8382\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.8408\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.8408\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.8408\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.8435\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.8515\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.8886\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.8727\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.8859\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.8833\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.9098\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.9098\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.9045\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.8966\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.9045\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.9178\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3551 - accuracy: 0.9125\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.9605\n",
            "--- Starting trial: run-5\n",
            "{'num_units': 64, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 3ms/step - loss: 3.8772 - accuracy: 0.0451\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.8401 - accuracy: 0.0928\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.8119 - accuracy: 0.1724\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7647 - accuracy: 0.2361\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7313 - accuracy: 0.2706\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6898 - accuracy: 0.2865\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6461 - accuracy: 0.2838\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.5919 - accuracy: 0.2865\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.5465 - accuracy: 0.2891\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.5128 - accuracy: 0.2918\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.4182 - accuracy: 0.2918\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.3701 - accuracy: 0.2918\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.2957 - accuracy: 0.2918\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.2548 - accuracy: 0.2918\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.1737 - accuracy: 0.2918\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.1209 - accuracy: 0.2918\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0951 - accuracy: 0.2918\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0497 - accuracy: 0.2918\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0172 - accuracy: 0.2918\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9823 - accuracy: 0.2918\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9521 - accuracy: 0.2918\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.9237 - accuracy: 0.2918\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8975 - accuracy: 0.2918\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8580 - accuracy: 0.2918\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8422 - accuracy: 0.2918\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8406 - accuracy: 0.2918\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7891 - accuracy: 0.2918\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7868 - accuracy: 0.2918\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7468 - accuracy: 0.2918\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7143 - accuracy: 0.2918\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7503 - accuracy: 0.2891\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7095 - accuracy: 0.2944\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6952 - accuracy: 0.2918\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6759 - accuracy: 0.2891\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6655 - accuracy: 0.2997\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6291 - accuracy: 0.2997\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6456 - accuracy: 0.2891\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6481 - accuracy: 0.2997\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6413 - accuracy: 0.2997\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6252 - accuracy: 0.2997\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5798 - accuracy: 0.2944\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5838 - accuracy: 0.3024\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5690 - accuracy: 0.3130\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5589 - accuracy: 0.3342\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5547 - accuracy: 0.3263\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5351 - accuracy: 0.3183\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5278 - accuracy: 0.3342\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5173 - accuracy: 0.3263\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.4863 - accuracy: 0.3607\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4795 - accuracy: 0.3554\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 2.4716 - accuracy: 0.3684\n",
            "--- Starting trial: run-6\n",
            "{'num_units': 64, 'dropout': 0.5, 'optimizer': 'adam'}\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.9087 - accuracy: 0.0265\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.7624 - accuracy: 0.1353\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.5982 - accuracy: 0.2387\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.3423 - accuracy: 0.2944\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.0829 - accuracy: 0.3024\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8571 - accuracy: 0.3210\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6905 - accuracy: 0.2971\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5867 - accuracy: 0.3236\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5071 - accuracy: 0.3395\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.3462 - accuracy: 0.3873\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2755 - accuracy: 0.4191\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1772 - accuracy: 0.4483\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1203 - accuracy: 0.4642\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.0616 - accuracy: 0.4775\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.9565 - accuracy: 0.5225\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.9586 - accuracy: 0.4934\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8385 - accuracy: 0.5199\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8108 - accuracy: 0.5199\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7096 - accuracy: 0.5703\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6557 - accuracy: 0.5703\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6582 - accuracy: 0.5676\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6022 - accuracy: 0.5915\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5082 - accuracy: 0.6154\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4581 - accuracy: 0.6313\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4698 - accuracy: 0.6127\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4158 - accuracy: 0.6207\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3678 - accuracy: 0.6631\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3686 - accuracy: 0.6313\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3343 - accuracy: 0.6578\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2676 - accuracy: 0.6631\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3218 - accuracy: 0.6525\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1860 - accuracy: 0.6923\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1628 - accuracy: 0.6897\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1993 - accuracy: 0.6764\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1106 - accuracy: 0.6950\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1316 - accuracy: 0.7029\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1325 - accuracy: 0.7135\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0581 - accuracy: 0.7268\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0421 - accuracy: 0.6976\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0160 - accuracy: 0.7480\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0483 - accuracy: 0.7109\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0185 - accuracy: 0.7321\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9332 - accuracy: 0.7507\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0063 - accuracy: 0.7241\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9545 - accuracy: 0.7321\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9078 - accuracy: 0.7507\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8896 - accuracy: 0.7666\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8862 - accuracy: 0.7533\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8752 - accuracy: 0.7666\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9018 - accuracy: 0.7427\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.8289\n",
            "--- Starting trial: run-7\n",
            "{'num_units': 64, 'dropout': 0.5, 'optimizer': 'sgd'}\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.9272 - accuracy: 0.0212\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.8644 - accuracy: 0.0531\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.8252 - accuracy: 0.0928\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.8000 - accuracy: 0.1220\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7438 - accuracy: 0.1485\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7106 - accuracy: 0.2095\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6660 - accuracy: 0.2175\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6289 - accuracy: 0.2546\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.5674 - accuracy: 0.2626\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.5271 - accuracy: 0.2838\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.4544 - accuracy: 0.2838\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.4097 - accuracy: 0.2785\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.3252 - accuracy: 0.2944\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.3126 - accuracy: 0.2891\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.2396 - accuracy: 0.2891\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.1357 - accuracy: 0.2944\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0780 - accuracy: 0.2918\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0849 - accuracy: 0.2918\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0187 - accuracy: 0.2891\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9830 - accuracy: 0.2918\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9932 - accuracy: 0.2891\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9522 - accuracy: 0.2891\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9318 - accuracy: 0.2891\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9043 - accuracy: 0.2891\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8814 - accuracy: 0.2944\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8855 - accuracy: 0.2918\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8119 - accuracy: 0.2891\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8512 - accuracy: 0.2918\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8656 - accuracy: 0.2812\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8164 - accuracy: 0.2997\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7984 - accuracy: 0.2918\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8139 - accuracy: 0.2891\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7985 - accuracy: 0.2944\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7204 - accuracy: 0.2838\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7398 - accuracy: 0.2944\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7223 - accuracy: 0.2865\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7606 - accuracy: 0.2918\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7044 - accuracy: 0.3156\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6593 - accuracy: 0.2997\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7501 - accuracy: 0.2944\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7217 - accuracy: 0.2971\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6831 - accuracy: 0.2997\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7035 - accuracy: 0.2944\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6678 - accuracy: 0.2891\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6102 - accuracy: 0.3316\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6032 - accuracy: 0.3130\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5969 - accuracy: 0.3103\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6085 - accuracy: 0.2944\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5851 - accuracy: 0.3342\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5742 - accuracy: 0.3103\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 2.5046 - accuracy: 0.3421\n",
            "--- Starting trial: run-8\n",
            "{'num_units': 128, 'dropout': 0.1, 'optimizer': 'adam'}\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.8430 - accuracy: 0.0902\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5048 - accuracy: 0.2997\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.0598 - accuracy: 0.2865\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6700 - accuracy: 0.2944\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4606 - accuracy: 0.3369\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3164 - accuracy: 0.3926\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1638 - accuracy: 0.4642\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0082 - accuracy: 0.5172\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9070 - accuracy: 0.5385\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7724 - accuracy: 0.5756\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6715 - accuracy: 0.5862\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5748 - accuracy: 0.6366\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4999 - accuracy: 0.6340\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3728 - accuracy: 0.6552\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3095 - accuracy: 0.6684\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2669 - accuracy: 0.6817\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1965 - accuracy: 0.7003\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0955 - accuracy: 0.7241\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1022 - accuracy: 0.7241\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0300 - accuracy: 0.7480\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9840 - accuracy: 0.7507\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9327 - accuracy: 0.7586\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8882 - accuracy: 0.7719\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8315 - accuracy: 0.7851\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7820 - accuracy: 0.8011\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7796 - accuracy: 0.7984\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6970 - accuracy: 0.8170\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6622 - accuracy: 0.8117\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.8355\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6036 - accuracy: 0.8488\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.8329\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.8541\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.8833\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.8753\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.8859\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.8833\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8912\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.9072\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3754 - accuracy: 0.9257\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8966\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.9151\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3408 - accuracy: 0.9125\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3458 - accuracy: 0.9204\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3370 - accuracy: 0.9231\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3248 - accuracy: 0.9231\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.9204\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 0.9178\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2748 - accuracy: 0.9310\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2413 - accuracy: 0.9416\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2550 - accuracy: 0.9523\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9868\n",
            "--- Starting trial: run-9\n",
            "{'num_units': 128, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.9724 - accuracy: 0.0239\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.9268 - accuracy: 0.0345\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.8996 - accuracy: 0.0265\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.8504 - accuracy: 0.0663\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.8081 - accuracy: 0.1167\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7746 - accuracy: 0.2042\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7330 - accuracy: 0.2599\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6994 - accuracy: 0.2759\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6522 - accuracy: 0.2865\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6084 - accuracy: 0.2997\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.5547 - accuracy: 0.2997\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.5158 - accuracy: 0.2971\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.4595 - accuracy: 0.2891\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.3885 - accuracy: 0.2918\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.3457 - accuracy: 0.2918\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.2827 - accuracy: 0.2918\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.2215 - accuracy: 0.2918\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.1427 - accuracy: 0.2918\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1063 - accuracy: 0.2918\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0318 - accuracy: 0.2918\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0067 - accuracy: 0.2918\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9524 - accuracy: 0.2918\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8911 - accuracy: 0.2918\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9004 - accuracy: 0.2918\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8593 - accuracy: 0.2918\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8274 - accuracy: 0.2918\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8302 - accuracy: 0.2918\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7683 - accuracy: 0.2918\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7592 - accuracy: 0.2918\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7251 - accuracy: 0.2918\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7212 - accuracy: 0.2918\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6990 - accuracy: 0.2944\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6995 - accuracy: 0.2918\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6904 - accuracy: 0.2997\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6473 - accuracy: 0.2944\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6516 - accuracy: 0.2944\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6380 - accuracy: 0.2971\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.6553 - accuracy: 0.2918\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6218 - accuracy: 0.2997\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5853 - accuracy: 0.3024\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5679 - accuracy: 0.3024\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.5468 - accuracy: 0.3210\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.5755 - accuracy: 0.3077\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5563 - accuracy: 0.3024\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5293 - accuracy: 0.3236\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5447 - accuracy: 0.3183\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.5634 - accuracy: 0.3210\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.4997 - accuracy: 0.3210\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.4991 - accuracy: 0.3528\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5154 - accuracy: 0.3289\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 2.5298 - accuracy: 0.3421\n",
            "--- Starting trial: run-10\n",
            "{'num_units': 128, 'dropout': 0.5, 'optimizer': 'adam'}\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7940 - accuracy: 0.1220\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5030 - accuracy: 0.2599\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1442 - accuracy: 0.2971\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8228 - accuracy: 0.3024\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6120 - accuracy: 0.3024\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4789 - accuracy: 0.3528\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3650 - accuracy: 0.3660\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2528 - accuracy: 0.4005\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1823 - accuracy: 0.4668\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0224 - accuracy: 0.5093\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9626 - accuracy: 0.5199\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8740 - accuracy: 0.5385\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7130 - accuracy: 0.5809\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6888 - accuracy: 0.5836\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6257 - accuracy: 0.6101\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5418 - accuracy: 0.6127\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4906 - accuracy: 0.6233\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4488 - accuracy: 0.6366\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4150 - accuracy: 0.6340\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3370 - accuracy: 0.6711\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2691 - accuracy: 0.6844\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2906 - accuracy: 0.6764\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2289 - accuracy: 0.6631\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1794 - accuracy: 0.6897\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1450 - accuracy: 0.7135\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1325 - accuracy: 0.7268\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0495 - accuracy: 0.7374\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0726 - accuracy: 0.7109\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0054 - accuracy: 0.7560\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0281 - accuracy: 0.7109\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9885 - accuracy: 0.7480\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9704 - accuracy: 0.7427\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9431 - accuracy: 0.7586\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9133 - accuracy: 0.7533\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8792 - accuracy: 0.7401\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8149 - accuracy: 0.7745\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8421 - accuracy: 0.7772\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8324 - accuracy: 0.7692\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7714 - accuracy: 0.7984\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7536 - accuracy: 0.8196\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7367 - accuracy: 0.8064\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7048 - accuracy: 0.7984\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7306 - accuracy: 0.8143\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.7958\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.8143\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6342 - accuracy: 0.8276\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.8355\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.8515\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.8276\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.8568\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.9211\n",
            "--- Starting trial: run-11\n",
            "{'num_units': 128, 'dropout': 0.5, 'optimizer': 'sgd'}\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.9225 - accuracy: 0.0239\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 3.8807 - accuracy: 0.0345\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.8620 - accuracy: 0.0424\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.8172 - accuracy: 0.1061\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7711 - accuracy: 0.1618\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.7266 - accuracy: 0.1883\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6816 - accuracy: 0.2361\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6471 - accuracy: 0.2706\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.6083 - accuracy: 0.2838\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.5447 - accuracy: 0.2653\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.5069 - accuracy: 0.2838\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.4443 - accuracy: 0.2891\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.3997 - accuracy: 0.2944\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.3400 - accuracy: 0.2891\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.2748 - accuracy: 0.2918\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.2229 - accuracy: 0.2918\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.1647 - accuracy: 0.2918\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0929 - accuracy: 0.2918\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0731 - accuracy: 0.2891\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0266 - accuracy: 0.2918\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0089 - accuracy: 0.2918\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9683 - accuracy: 0.2918\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9499 - accuracy: 0.2918\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9646 - accuracy: 0.2918\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9033 - accuracy: 0.2918\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9077 - accuracy: 0.2918\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.8702 - accuracy: 0.2944\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8456 - accuracy: 0.2891\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8360 - accuracy: 0.2918\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8051 - accuracy: 0.2891\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.8098 - accuracy: 0.2918\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7640 - accuracy: 0.2971\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7803 - accuracy: 0.2944\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7593 - accuracy: 0.2891\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7805 - accuracy: 0.2918\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7524 - accuracy: 0.3024\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7189 - accuracy: 0.2944\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7189 - accuracy: 0.3024\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2.7110 - accuracy: 0.2944\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6809 - accuracy: 0.2918\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6801 - accuracy: 0.2944\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7006 - accuracy: 0.2997\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6354 - accuracy: 0.2971\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6571 - accuracy: 0.3024\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6315 - accuracy: 0.2971\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6158 - accuracy: 0.2997\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5927 - accuracy: 0.3024\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6354 - accuracy: 0.3077\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5678 - accuracy: 0.3130\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6148 - accuracy: 0.2997\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 2.5765 - accuracy: 0.3158\n"
          ]
        }
      ],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/\n",
        "\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "\n",
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([32, 64, 128]))\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.5))\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
        "\n",
        "METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "  )\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = list(training[:, 0])\n",
        "Y = list(training[:, 1])\n",
        "\n",
        "x_train,x_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
        "x_train = X\n",
        "y_train = Y \n",
        "\n",
        "session_num = 0\n",
        "\n",
        "def train_test_model(hparams):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_shape=input_shape, activation=\"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(hparams[HP_NUM_UNITS], activation=\"relu\"))\n",
        "    model.add(Dropout(hparams[HP_DROPOUT]))\n",
        "    model.add(Dense(output_shape, activation=\"softmax\"))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=hparams[HP_OPTIMIZER],\n",
        "                metrics=[\"accuracy\"]) \n",
        "\n",
        "    model.fit(x_train, y_train, epochs=50) # Run with 1 epoch to speed things up for demo purposes_, \n",
        "\n",
        "    accuracy = model.evaluate(x_test, y_test)\n",
        "    return accuracy[1]\n",
        "\n",
        "def run(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    accuracy = train_test_model(hparams)\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
        "\n",
        "for num_units in HP_NUM_UNITS.domain.values:\n",
        "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
        "    for optimizer in HP_OPTIMIZER.domain.values:\n",
        "      hparams = {\n",
        "          HP_NUM_UNITS: num_units,\n",
        "          HP_DROPOUT: dropout_rate,\n",
        "          HP_OPTIMIZER: optimizer,\n",
        "      }\n",
        "      run_name = \"run-%d\" % session_num\n",
        "      print('--- Starting trial: %s' % run_name)\n",
        "      print({h.name: hparams[h] for h in hparams})\n",
        "      run('logs/hparam_tuning/' + run_name, hparams)\n",
        "      session_num += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJhTrJ7Ix1Td"
      },
      "source": [
        "# Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "13-xAZPoU0iX"
      },
      "outputs": [],
      "source": [
        "# Text cosine similiarity\n",
        "def get_cosine(vec1, vec2):\n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
        "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "    if not denominator:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return float(numerator) / (denominator)\n",
        "\n",
        "\n",
        "def text_to_vector(text):\n",
        "    word = re.compile(r'\\w+')\n",
        "    words = word.findall(text)\n",
        "    return Counter(words)\n",
        "\n",
        "\n",
        "def kesamaan(content_a, content_b):\n",
        "    text1 = \" \".join(content_a)\n",
        "    text2 = \" \".join(content_b)\n",
        "\n",
        "    vector1 = text_to_vector(text1)\n",
        "    vector2 = text_to_vector(text2)\n",
        "\n",
        "    cosine_result = get_cosine(vector1, vector2)\n",
        "    return cosine_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "AKulXJyip7kt"
      },
      "outputs": [],
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "def stem_text(text):\n",
        "    # sastrawi stemmer\n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "    return stemmer.stem(text)\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [word for word in tokens]\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def bag_of_words(text, vocab):\n",
        "    tokens = clean_text(text)\n",
        "    bow = [0] * len(vocab)\n",
        "    for w in tokens:\n",
        "        for idx, word in enumerate(vocab):\n",
        "            if kesamaan(word,w) > 0.90:\n",
        "                print(word,'<=>',w,kesamaan(word,w))\n",
        "                bow[idx] = 1\n",
        "    return np.array(bow)\n",
        "\n",
        "\n",
        "def pred_class(text, vocab, labels):\n",
        "    bow = bag_of_words(text, vocab)\n",
        "    result = model.predict(np.array([bow]))[0]\n",
        "    print(bow)\n",
        "    # melakukan iterasi dari seluruh kemungkinan kelas\n",
        "    thresh = 0.5\n",
        "    y_pred = [[idx, res] for idx, res in enumerate(result) if res > thresh]\n",
        "\n",
        "    y_pred.sort(key=lambda x: x[1], reverse=True)\n",
        "    print(y_pred)\n",
        "    return_list = []\n",
        "\n",
        "    for r in y_pred:\n",
        "        return_list.append(labels[r[0]])\n",
        "    if (len(return_list)) == 0:\n",
        "        return [\"no_response\"]\n",
        "    else:\n",
        "        return return_list\n",
        "\n",
        "def pred_class_ml(text, vocab, labels):\n",
        "    bow = bag_of_words(text, vocab)\n",
        "    result = model_ml.predict(np.array([bow]))[0]\n",
        "    thresh = 0.5\n",
        "    y_pred = [[idx, res] for idx, res in enumerate(result) if res > thresh]\n",
        "\n",
        "    y_pred.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "\n",
        "    for r in y_pred:\n",
        "        return_list.append(labels[r[0]])\n",
        "    if (len(return_list)) == 0:\n",
        "        return [\"no_response\"]\n",
        "    else:\n",
        "        return return_list\n",
        "\n",
        "\n",
        "def get_response(intents_list, intents_json):\n",
        "    tag = intents_list[0]\n",
        "    list_of_intents = intents_json[\"intents\"]\n",
        "    for i in list_of_intents:\n",
        "        if i[\"tag\"] == tag:\n",
        "            result = random.choice(i[\"responses\"])\n",
        "            break\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZieDcn9xycQ"
      },
      "source": [
        "# Test reponse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "FsgAki2qn8TA",
        "outputId": "05670c38-8ed0-4673-bff0-172ac6491d8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bayar ukt gagal\n",
            "abar <=> bayar 0.9258200997725514\n",
            "bayar <=> bayar 0.9999999999999999\n",
            "ukt <=> ukt 1.0000000000000002\n",
            "gagal <=> gagal 1.0\n",
            "tanggal <=> gagal 0.9045340337332909\n",
            "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[[44, 0.9999168]]\n",
            "['tata cara pembayaran']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Untuk melakukan pembayaran UKT, SPP, IPI dapat dilihat pada laman https://selma.ub.ac.id/tata-cara-pembayaran/https://selma.ub.ac.id/tata-cara-pembayaran/'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "intext = input(\"Masukkan : \")\n",
        "intext = stem_text(intext)\n",
        "print(intext)\n",
        "intent = pred_class(intext, words, classes)\n",
        "print(intent)\n",
        "get_response(intent,data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq0iVJCJxw9j"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yzz7rfek9yTJ"
      },
      "outputs": [],
      "source": [
        "model.save('model_chatbot.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6ttW-MDxDe8"
      },
      "outputs": [],
      "source": [
        "pickle.dump(model_ml,open('modelml_chatbot.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "65hOpSi60HzK",
        "outputId": "dbe9bd58-e98c-488b-e3ea-e998f271bf29"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.0'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pickle.format_version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAGAfOtLnlGx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpGT430caM-s"
      },
      "source": [
        "# Experiment text similiarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUp3NzrQLpd_",
        "outputId": "6a53e990-9600-4661-b3dd-c8039d19be4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9058216273156767"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kesamaan('agastya','saya')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRqXp2o02IKa",
        "outputId": "07f70a27-28fb-42ac-99e9-71405299f63c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.82502864732539"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kesamaan('siswa','mahasiswa')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejvaHp6OdSQ2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "28eae9bd557633d1da885b313a415d212381d0b87dac30d636aacc2df031352f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
